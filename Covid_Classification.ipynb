{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNY15KVhBSUbJbw4OXDl9Zi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rigved19/Covid-Classification-Using-X-Ray-Images/blob/main/Covid_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V21yb54ZJiAi",
        "outputId": "65974e30-5c89-4f51-ec79-50bddf295fd8"
      },
      "source": [
        "!pip install Pillow"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8pbmLIfv-0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234ecca8-07df-4f42-ae5d-b9a28b128f73"
      },
      "source": [
        "#Mounting Google Drive to Colab NoteBook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkqsZnInwEE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2034ac56-a54b-4a07-bf91-e29320ab3ff0"
      },
      "source": [
        "#Extracting all files from the zip file\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/CovidDataset (1).zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Completed\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHm7NzHjFinF"
      },
      "source": [
        "###Building CNN Model\n",
        "\n",
        "*  Convolution Layer\n",
        "*  Pooling Layer\n",
        "*  Artificial Neural Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emygN6KWwFYQ"
      },
      "source": [
        "#Importing all layers and models from Keras \n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import * \n",
        "import tensorflow.keras as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnR-u0MwwFfT"
      },
      "source": [
        "#Training model\n",
        "model = Sequential()   ## Creating a blank model\n",
        "\n",
        "#Adding Convolution Layer with 32 feauture detectors and reshaping input to specified size\n",
        "#Adding Pooling Layer\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(224,224,3)))  \n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "#Addition of Convolutional and Pooling Layers (Optimum number found by trial and error)\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))  #Using double no. of feature detectors\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))                       #Reduce the overfitting\n",
        " \n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#ANN Network starts \n",
        "model.add(Flatten())                      #Input Layer\n",
        "model.add(Dense(64,activation='relu'))    #Hidden Layer of ANN\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation='sigmoid'))   #Output Layer\n",
        "\n",
        "#Since it's a binary classification problem \n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy']) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDSMHj0rFx5-"
      },
      "source": [
        "##Image Preprocessing and Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgyB0eawFhX"
      },
      "source": [
        "#Image Preprocessing AND Daata Augmentation\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#Rescale -Similar to Normalization [0,255) --> [0,1]\n",
        "#Shear Range -Creates rotated images\n",
        "#Zoom Range -Creates zoomed images\n",
        "\n",
        "train_datagen = image.ImageDataGenerator(rescale = 1./255, shear_range = 0.2,zoom_range = 0.2, horizontal_flip = True) #Training Instance\n",
        " \n",
        "test_dataset = image.ImageDataGenerator(rescale=1./255)  #Validation Instance"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxMLAfCqF7qP"
      },
      "source": [
        "###Creating training and validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nsbhFDOwFju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab249b2-bea2-43ec-a488-06241ff1bd32"
      },
      "source": [
        "#Reshaping Training and Validation images\n",
        "\n",
        "#Creating training images\n",
        "train_generator = train_datagen.flow_from_directory(     \n",
        "    '/content/CovidDataset/Train',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "#Creating testing images\n",
        "validation_generator = test_dataset.flow_from_directory(\n",
        "    '/content/CovidDataset/Val',\n",
        "    target_size = (224,224),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 224 images belonging to 2 classes.\n",
            "Found 60 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nmMYsztGFQ6"
      },
      "source": [
        "Training the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EYavT0CwFly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d203a420-88ad-4ee2-d143-b195cc707f99"
      },
      "source": [
        "#Train the model\n",
        "\n",
        "#Printing test and validation loss and accuracy at the same time\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=7,\n",
        "    epochs = 20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps=1\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "7/7 [==============================] - 40s 1s/step - loss: 0.7185 - accuracy: 0.5625 - val_loss: 0.6916 - val_accuracy: 0.5312\n",
            "Epoch 2/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6806 - accuracy: 0.5446 - val_loss: 0.6817 - val_accuracy: 0.5625\n",
            "Epoch 3/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6215 - accuracy: 0.6964 - val_loss: 0.5868 - val_accuracy: 0.9062\n",
            "Epoch 4/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.4713 - accuracy: 0.7634 - val_loss: 0.3368 - val_accuracy: 0.9688\n",
            "Epoch 5/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3172 - accuracy: 0.8616 - val_loss: 0.1863 - val_accuracy: 0.9688\n",
            "Epoch 6/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3417 - accuracy: 0.8973 - val_loss: 0.2630 - val_accuracy: 0.9062\n",
            "Epoch 7/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2617 - accuracy: 0.8929 - val_loss: 0.1465 - val_accuracy: 0.9688\n",
            "Epoch 8/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2568 - accuracy: 0.8795 - val_loss: 0.1451 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1721 - accuracy: 0.9509 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1865 - accuracy: 0.9241 - val_loss: 0.0891 - val_accuracy: 0.9688\n",
            "Epoch 11/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1158 - accuracy: 0.9688 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1167 - accuracy: 0.9509 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1135 - accuracy: 0.9509 - val_loss: 0.0355 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1108 - accuracy: 0.9688 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0933 - accuracy: 0.9821 - val_loss: 0.0552 - val_accuracy: 0.9688\n",
            "Epoch 16/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.0686 - accuracy: 0.9777 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1041 - accuracy: 0.9688 - val_loss: 0.0412 - val_accuracy: 0.9688\n",
            "Epoch 18/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1203 - accuracy: 0.9732 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1061 - accuracy: 0.9598 - val_loss: 0.0664 - val_accuracy: 0.9688\n",
            "Epoch 20/20\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1282 - accuracy: 0.9688 - val_loss: 0.0960 - val_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uXxwDvYIcJq"
      },
      "source": [
        "Testing Model with random X-Ray image from net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWRVsv5xwFoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cb4248-ef56-49e8-d131-91fcff9ab749"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "img = image.load_img('/content/test_image.jpeg',target_size=(224,224)) #Loading Image \n",
        "img = image.img_to_array(img)      # \n",
        "img = np.expand_dims(img,axis=0)   # Flattening\n",
        "ypred = model.predict(img)\n",
        "if ypred[0][0] == 1:\n",
        "  print(\"Covid Negative\")\n",
        "else:\n",
        "  print(\"Covid Positive\")\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Covid Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hopz-R4dwFtI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS4z_22ZwFvi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}